{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imamWWG6Qxqa",
        "outputId": "b3925f8d-c8c3-49ec-f54a-d3e9ecba23ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.9/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pytorch-nlp) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pytorch-nlp) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w9WilzwQlgr",
        "outputId": "469df4a5-d8be-4d83-8c30-7f17d7b9223d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import pandas as pd\n",
        "from torchnlp.datasets import imdb_dataset\n",
        "import random\n",
        "import string \n",
        "import re\n",
        "import math\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# download stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and preprocessing data "
      ],
      "metadata": {
        "id": "lLmtrQIVCuSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0ZJD7n3VRPui",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "491feb15-cf46-4ddf-df67-0815cc93cb55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text sentiment\n",
              "0  n't get wrong assume movie would stupid honest...       neg\n",
              "1  movie almost generation-defining importance be...       pos\n",
              "2  previously see abridge print present david she...       pos\n",
              "3  jane porter former love interest harry holt ne...       pos\n",
              "4  admit tsui hark one kind n't top person strong...       pos"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1876d33-a987-4800-a55f-800ca5498e83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n't get wrong assume movie would stupid honest...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>movie almost generation-defining importance be...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>previously see abridge print present david she...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jane porter former love interest harry holt ne...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>admit tsui hark one kind n't top person strong...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1876d33-a987-4800-a55f-800ca5498e83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1876d33-a987-4800-a55f-800ca5498e83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1876d33-a987-4800-a55f-800ca5498e83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# load dataset\n",
        "train_long = imdb_dataset(train=True)\n",
        "test_long = imdb_dataset(test=True)\n",
        "random.shuffle(train_long)\n",
        "random.shuffle(test_long)\n",
        "train = []\n",
        "test = []\n",
        "\n",
        "# only use a subsample of the data as to not run into memory overflow errors\n",
        "for i in range(2000):\n",
        "  train.append(train_long[i])\n",
        "\n",
        "for i in range(500):\n",
        "  test.append(test_long[i])\n",
        "\n",
        "df_train = pd.DataFrame.from_dict(train)\n",
        "df_test =  pd.DataFrame.from_dict(test)\n",
        "\n",
        "# clean and tokenize textual data\n",
        "def clean_data(words):\n",
        "  #Set to lower case\n",
        "  words = words.lower()\n",
        "\n",
        "  # removing all the html tags from our data\n",
        "  words = re.sub(r'<.*?>', '', words)\n",
        "\n",
        "  # remove numbers\n",
        "  words = re.sub(r'\\d+', '', words)\n",
        "\n",
        "  #Get rid of all punctiation and stop words\n",
        "  no_punc = []\n",
        "  tokens = nltk.word_tokenize(words)\n",
        "\n",
        "  for w in tokens:\n",
        "    if len(w) > 2 and w not in stopwords.words('english') and w not in set(string.punctuation): \n",
        "      no_punc.append(w)\n",
        "    \n",
        "  words = ' '.join(no_punc)\n",
        "  words = words.strip()\n",
        "\n",
        "  #Lemmatizes the words, puts the words in their most \n",
        "  #Basic form \n",
        "  lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "  lemmas = []\n",
        "\n",
        "  for w in nltk.word_tokenize(words):\n",
        "    lem = lemmatizer.lemmatize(w, pos=\"v\")\n",
        "\n",
        "    if len(lem) > 2: \n",
        "      lemmas.append(lem)\n",
        "  \n",
        "  words = ' '.join(lemmas)\n",
        "  return words.strip()\n",
        "\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(clean_data)\n",
        "df_test['text'] = df_test['text'].apply(clean_data)\n",
        "\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes binary classification model"
      ],
      "metadata": {
        "id": "93DFuPvpDA_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tables.utils import count_logged_instances\n",
        "\n",
        "\n",
        "class naive_bayes():\n",
        "\n",
        "  def __init__(self):\n",
        "    #Total number of words associated \n",
        "    #with positive or negative sentiment \n",
        "    self.num_messages = {}\n",
        "    #Holds the priors for positive and \n",
        "    #negaitbe sentiment\n",
        "    self.log_class_priors = {}\n",
        "    #Holds the counts of each word in \n",
        "    #the data\n",
        "    self.word_counts = {}\n",
        "    #The vocabulary of our data \n",
        "    #i.e all the words seen during training \n",
        "    self.vocab = set()\n",
        "\n",
        "    self.total_words = {}\n",
        "\n",
        "  #Helper method to get the total counts of \n",
        "  #each word out of a sentance\n",
        "  def get_word_counts(self, words):\n",
        "    counts = {}\n",
        "    for w in words: \n",
        "      counts[w] = counts.get(w, 0.0) + 1.0\n",
        "\n",
        "    return counts\n",
        "\n",
        "\n",
        "  def fit(self, data):\n",
        "\n",
        "    #Gets the total number of positive and negative messages\n",
        "    self.num_messages['pos'] = len(data[data['sentiment'] == 'pos'])\n",
        "    self.num_messages['neg'] = len(data[data['sentiment'] == 'neg'])\n",
        "\n",
        "    #Set up our priors which in this case are bernoulli r.v \n",
        "    #Get one for both pos and neg reviews\n",
        "    self.log_class_priors['pos'] = math.log(self.num_messages['pos'] / len(data))\n",
        "    self.log_class_priors['neg'] = math.log(self.num_messages['neg'] / len(data))\n",
        "    \n",
        "\n",
        "    #Get's the total count of every word in our training dataset\n",
        "    #For both positive and negative reviews \n",
        "    self.word_counts['pos'] = {}\n",
        "    self.word_counts['neg'] = {}\n",
        "    self.total_words['pos'] = 0\n",
        "    self.total_words['neg'] = 0\n",
        "\n",
        "    for cur_text, cur_sent in zip(data['text'], data['sentiment']):\n",
        "\n",
        "        counts = self.get_word_counts(nltk.word_tokenize(cur_text))\n",
        "        for word, count in counts.items():\n",
        "            if word not in self.vocab:\n",
        "                self.vocab.add(word)\n",
        "            if word not in self.word_counts[cur_sent]:\n",
        "                self.word_counts[cur_sent][word] = 0.0\n",
        " \n",
        "            self.word_counts[cur_sent][word] += count\n",
        "            self.total_words[cur_sent] += count\n",
        "\n",
        "    \n",
        "\n",
        "  def predict(self, pred_data):\n",
        "    pred = []\n",
        "\n",
        "    #Go through each text to get a prediction\n",
        "    for cur in pred_data:\n",
        "      counts = self.get_word_counts(nltk.word_tokenize(cur))\n",
        "      pos_score = 0\n",
        "      neg_score = 0\n",
        "\n",
        "      for cur_word, _ in counts.items():\n",
        "        #If we have no seen this word during training skip it\n",
        "        if cur_word not in self.vocab: \n",
        "          continue\n",
        "        \n",
        "        #Finding our multinomial liklehood for pos and neg \n",
        "        #with laplace smoothing \n",
        "\n",
        "        log_pos = math.log((self.word_counts['pos'].get(cur_word, 0.0) + 1) / (self.num_messages['pos'] + len(self.vocab)))\n",
        "        #log_pos = math.log((self.word_counts['pos'].get(cur_word, 0.0) + 1) / (self.total_words['pos']))\n",
        "\n",
        "        log_neg = math.log((self.word_counts['neg'].get(cur_word, 0.0) + 1) / (self.num_messages['neg'] + len(self.vocab)))\n",
        "        #log_neg = math.log((self.word_counts['neg'].get(cur_word, 0.0) + 1) / (self.total_words['neg']))\n",
        "\n",
        "        #Add the likleihood term to our total \n",
        "        #Scores for pos and neg \n",
        "        pos_score += log_pos\n",
        "\n",
        "        neg_score += log_neg\n",
        "\n",
        "      #Add our priors to our score\n",
        "      pos_score += self.log_class_priors['pos']\n",
        "      neg_score += self.log_class_priors['neg']\n",
        "\n",
        "      #pick the larger score \n",
        "      if pos_score > neg_score:\n",
        "          pred.append('pos')\n",
        "      else:\n",
        "          pred.append('neg')\n",
        "    return pred\n",
        "\n",
        "\n",
        "  def evaluate_acc(self, y_true, y_pred):\n",
        "    total = 0\n",
        "    for count, _ in enumerate(y_pred):\n",
        "      if y_true[count] == y_pred[count]:\n",
        "        total += 1\n",
        "      acc = total/len(y_pred)\n",
        "\n",
        "    print(acc)\n",
        "    return classification_report(y_true, y_pred)\n",
        "\n",
        "\n",
        "NB = naive_bayes()\n",
        "\n",
        "NB.fit(df_train)\n",
        "\n",
        "pred_text = df_test[\"text\"]\n",
        "\n",
        "preds = NB.predict(pred_text)\n",
        "\n",
        "\n",
        "acc = NB.evaluate_acc(df_test[\"sentiment\"], preds)\n",
        "print(acc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sPJawBkgd70",
        "outputId": "df83bea4-f01b-4985-f4ba-e69892f7c2b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.778\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.92      0.61      0.74       253\n",
            "         pos       0.70      0.95      0.81       247\n",
            "\n",
            "    accuracy                           0.78       500\n",
            "   macro avg       0.81      0.78      0.77       500\n",
            "weighted avg       0.82      0.78      0.77       500\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}